# -*- coding: utf-8 -*-
"""
:created: 22 Feb 2013
:author: Rinze de Laat
:copyright: Â© 2013 Rinze de Laat, Delmic

This file is part of Odemis.

.. license::
    Odemis is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License version 2 as published
    by the Free Software Foundation.

    Odemis is distributed in the hope that it will be useful, but WITHOUT ANY
    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
    FOR A PARTICULAR PURPOSE. See the GNU General Public License for more
    details.

    You should have received a copy of the GNU General Public License along with
    Odemis. If not, see http://www.gnu.org/licenses/.



This module contains classes that describe Streams, which are basically
Detector, Emitter and Dataflow associations.

"""

from __future__ import division

from abc import ABCMeta, abstractmethod
import collections
from concurrent.futures._base import CancelledError, CANCELLED, FINISHED, \
    RUNNING
import logging
import math
import numpy
from numpy.polynomial import polynomial
from odemis.gui.model.img import InstrumentalImage
from odemis.gui.util.img import NDImage2wxImage
from odemis.model import VigilantAttribute, MD_POS, MD_PIXEL_SIZE, \
    MD_SENSOR_PIXEL_SIZE, MD_WL_POLYNOMIAL, MD_DESCRIPTION
from odemis.util import TimeoutError, limit_invocation, polar
import sys
import threading
import time

import odemis.gui.util.conversion as conversion
import odemis.model as model
import odemis.util.img as img
import odemis.util.units as units


# to identify a ROI which must still be defined by the user
UNDEFINED_ROI = (0, 0, 0, 0)

#pylint: disable=W0221

class Stream(object):
    """ A stream combines a Detector, its associated Dataflow and an Emitter.

    It handles acquiring the data from the hardware and renders it as an
    InstrumentalImage with the given image transformation.

    This is an abstract class, unless the emitter doesn't need any configuration
    (always on, with the right settings).

    Note: If a Stream needs multiple Emitters, then this should be implemented
    in a subclass of Stream.
    """

    WARNING_EXCITATION_NOT_OPT = ("The excitation wavelength selected cannot "
                                  "be optimally generated by the hardware.")
    WARNING_EXCITATION_IMPOSSIBLE = ("The excitation wavelength selected "
                                     "cannot be generated by the hardware.")
    WARNING_EMISSION_NOT_OPT = ("The emission wavelength selected cannot be "
                                "optimally detected by the hardware.")
    WARNING_EMISSION_IMPOSSIBLE = ("The emission wavelength selected cannot be "
                                   "detected by the hardware.")

    # Minimum overhead time in seconds when acquiring an image
    SETUP_OVERHEAD = 0.1

    def __init__(self, name, detector, dataflow, emitter):
        """
        name (string): user-friendly name of this stream
        detector (Detector): the detector which has the dataflow
        dataflow (Dataflow): the dataflow from which to get the data
        emitter (Emitter): the emitter
        """

        self.name = model.StringVA(name)

        # Hardware Components
        self._detector = detector
        self._emitter = emitter

        # Dataflow (Live image stream with meta data)
        # Note: A Detectors can have multiple dataflows, so that's why a Stream
        # has a separate attribute.
        self._dataflow = dataflow

        self._running_upd_img = False # to avoid simultaneous updates in different threads
        # list of DataArray received and used to generate the image
        # every time it's modified, image is also modified
        self.raw = []
        # the most important attribute
        self.image = model.VigilantAttribute(InstrumentalImage(None))

        # TODO: should maybe to 2 methods activate/deactivate to explicitly
        # start/stop acquisition, and one VA "updated" to stated that the user
        # want this stream updated (as often as possible while other streams are
        # also updated)
        # should_update has no effect direct effect, it's just a flag to
        # indicate the user would like to have the stream updated (live)
        self.should_update = model.BooleanVA(False)
        # is_active set to True will keep the acquisition going on
        self.is_active = model.BooleanVA(False)
        self.is_active.subscribe(self.onActive)

        # Region of interest as left, top, right, bottom (in ratio from the
        # whole area of the emitter => between 0 and 1)
        self.roi = model.TupleContinuous((0, 0, 1, 1),
                                         range=((0, 0, 0, 0), (1, 1, 1, 1)),
                                         cls=(int, long, float))

        self._irange = None
        self._updateIRange()

        # whether to use auto brightness & contrast
        self.auto_bc = model.BooleanVA(True)
        # % of values considered outliers discarded in auto BC detection
        # Note: 1/256th is a nice value because on RGB, it means in degenerated
        # cases (like flat histogram), you still loose only one value on each
        # side.
        self.auto_bc_outliers = model.FloatContinuous(100 / 256, range=(0, 40))

        # Used if auto_bc is False
        # min/max ratio of the whole intensity level which are mapped to
        # black/white. The .histogram always has
        # the first value mapped to 0 and last value mapped to 1.
        self.intensityRange = model.TupleContinuous((0, 1),
                                                    range=((0, 0), (1, 1)),
                                                    cls=(int, long, float))

        # Histogram of the current image _or_ slightly older image.
        # Note it's an ndarray. Use .tolist() to get a python list.
        self.histogram = model.VigilantAttribute(numpy.ndarray(0), readonly=True)
        self.histogram._full_hist = numpy.ndarray(0) # for finding the outliers
        self.histogram._edges = self._irange # TODO: needed?

        self.auto_bc.subscribe(self._onAutoBC)
        self.auto_bc_outliers.subscribe(self._onOutliers) # FIXME
        self.intensityRange.subscribe(self._onIntensityRange)
        self._ht_needs_recompute = threading.Event()
        self._htread = threading.Thread(target=self._histogram_thread,
                                        name="Histogram computation")
        self._htread.daemon = True
        self._htread.start()

        # self.histogram.subscribe(self._onHistogram) # FIXME -> update outliers and then image

        # list of warnings to display to the user
        # TODO should be a set
        self.warnings = model.ListVA([]) # should only contain WARNING_*

    @property
    def emitter(self):
        return self._emitter

    def __str__(self):
        return "%s %s" % (self.__class__.__name__, self.name.value)

    def estimateAcquisitionTime(self):
        """ Estimate the time it will take to acquire one image with the current
        settings of the detector and emitter.

        returns (float): approximate time in seconds that acquisition will take
        """
        # This default implementation returns the shortest possible time, taking
        # into account a minimum overhead. (As in, acquisition will never take
        # less than 0.1 seconds)
        return self.SETUP_OVERHEAD

    def _removeWarnings(self, *warnings):
        """ Remove all the given warnings if any are present

        warnings (set of WARNING_*): the warnings to remove
        """
        new_warnings = set(self.warnings.value) - set(warnings)
        self.warnings.value = list(new_warnings)

    def _addWarning(self, warning):
        """ Add a warning if not already present

        warning (WARNING_*): the warning to add
        """
        if not warning in self.warnings.value:
            self.warnings.value.append(warning)

    def onActive(self, active):
        """ Called when the Stream is activated or deactivated by setting the
        is_active attribute
        """
        if active:
            msg = "Subscribing to dataflow of component %s"
            logging.debug(msg, self._detector.name)
            if not self.should_update.value:
                logging.warning("Trying to activate stream while it's not "
                                "supposed to update")
            self._dataflow.subscribe(self.onNewImage)
        else:
            msg = "Unsubscribing from dataflow of component %s"
            logging.debug(msg, self._detector.name)
            self._dataflow.unsubscribe(self.onNewImage)

    # No __del__: subscription should be automatically stopped when the object
    # disappears, and the user should stop the update first anyway.

    def _updateIRange(self):
        """
        Update the ._irange, with whatever data is known so far.
        """
        # 2 types of irange management:
        # * dtype is int -> follow MD_BPP/shape/dtype.max
        # * dtype is float -> always increase, starting from 0-depth
        if self.raw:
            data = self.raw[0]
            if data.dtype.kind in "biu":
                if model.MD_BPP in data.metadata:
                    depth = 2**data.metadata[model.MD_BPP]
                    if data.dtype.kind == "i":
                        irange = (-depth // 2, depth // 2 - 1)
                    else:
                        irange = (0, depth - 1)
                elif self._detector:
                    depth = self._detector.shape[-1]
                    if data.dtype.kind == "i":
                        irange = (-depth // 2, depth // 2 - 1)
                    else:
                        irange = (0, depth - 1)
                else:
                    idt = numpy.iinfo(data.dtype)
                    irange = (idt.min, idt.max)
            else: # float
                # cast to ndarray to ensure a scalar (instead of a DataArray)
                irange = (numpy.array(data).min(), numpy.array(data).max())
                if self._irange is not None:
                    irange = (min(irange[0], self._irange[0]),
                              max(irange[1], self._irange[1]))
        else:
            # no data, assume it's uint
            if self._detector:
                # The last element of the shape indicates the bit depth, which
                # is used for brightness/contrast adjustment.
                irange = (0, self._detector.shape[-1] - 1)
            else:
                irange = None

        self._irange = irange

    def _getDisplayIRange(self):
        """
        return the min/max values to display. It also updates the intensityRange
         VA if needed.
        """
        if self.auto_bc.value:
            # The histogram might be slightly old, but not too much
            irange = img.findOptimalRange(self.histogram._full_hist,
                                          self.histogram._edges,
                                          self.auto_bc_outliers.value / 100)

            # Also update the intensityRanges if auto BC
            edges = self.histogram._edges
            rrange = [(v - edges[0]) / (edges[1] - edges[0]) for v in irange]
            self.intensityRange.value = tuple(rrange)
        else:
            # just convert from the user-defined (as ratio) to actual values
            rrange = sorted(self.intensityRange.value)
            edges = self.histogram._edges
            irange = [edges[0] + (edges[1] - edges[0]) * v for v in rrange]

        return irange

    def _findPos(self, data):
        """
        Find the (center) position of the given image. Guess if necessary.
        data (DataArray): image
        return (tuple of float): position
        """
        try:
            pos = data.metadata[MD_POS]
        except KeyError:
            # Note: this log message is disabled to prevent log flooding
            # logging.warning("Position of image unknown")
            pos = (0, 0)
        return pos

    def _findMPP(self, data):
        """
        Find the density of the given image. Guess if necessary.
        data (DataArray): image
        return (tuple of float): MPP per dimension
        """
        try:
            mpp = data.metadata[MD_PIXEL_SIZE][0]
        except KeyError:
            try:
                # Hopefully it'll be within the same magnitude
                mpp = (data.metadata[MD_SENSOR_PIXEL_SIZE][0]
                        * data.metadata.get(model.MD_BINNING, (1, 1))[0])
                # Note: this log message is disabled to prevent log flooding
                # msg = "Pixel density of image unknown, using sensor size"
                # logging.warning(msg)
            except KeyError:
                logging.error("Image has no pixel density known")
                mpp = 20e-6 # m/px (typical sensor size)

        return mpp

    @limit_invocation(0.1) # Max 10 Hz
    def _updateImage(self, tint=(255, 255, 255)):
        """ Recomputes the image with all the raw data available

        tint ((int, int, int)): colouration of the image, in RGB. Only used by
            FluoStream to avoid code duplication
        """
        # check to avoid running it if there is already one running
        if self._running_upd_img or not self.raw:
            return

        try:
            self._running_upd_img = True
            data = self.raw[0]
            irange = self._getDisplayIRange()
            rgbim = img.DataArray2RGB(data, irange, tint)
            im = NDImage2wxImage(rgbim)
            im.InitAlpha() # it's a different buffer so useless to do it in numpy

            self.image.value = InstrumentalImage(im,
                                                 self._findMPP(data),
                                                 self._findPos(data))
        except Exception:
            logging.exception("Updating %s image", self.__class__.__name__)
        finally:
            self._running_upd_img = False

    def _onAutoBC(self, enabled):
        # if changing to auto: B/C might be different from the manual values
        if enabled == True:
            self._updateImage()

    def _onOutliers(self, outliers):
        if self.auto_bc.value == True:
            self._updateImage()

    def _onIntensityRange(self, irange):
        # If auto_bc is active, it updates intensities (from _updateImage()),
        # so no need to refresh image again.
        if self.auto_bc.value == False:
            self._updateImage()

    def _shouldUpdateHistogram(self):
        """
        Ensures that the histogram VA will be updated in the "near future".
        """
        # If the previous request is still being processed, the event
        # synchronization allows to delay it (without accumulation).
        self._ht_needs_recompute.set()

    def _updateHistogram(self, data=None):
        """
        data (DataArray): the raw data to use, default to .raw[0]
        """
        # Compute histogram and compact version
        if not self.raw and not data:
            return

        data = self.raw[0] if data is None else data
        # Initially, _irange might be None, in which case it will be guessed
        hist, edges = img.histogram(data, irange=self._irange)
        if hist.size > 256:
            chist = img.compactHistogram(hist, 256)
        else:
            chist = hist
        self.histogram._full_hist = hist
        self.histogram._edges = edges
        # Read-only VA, so we need to go around...
        self.histogram._value = chist
        self.histogram.notify(chist)

    def _histogram_thread(self):
        """
        Called as a separate thread, and recomputes the histogram whenever
        it receives an event asking for it.
        """
        while True:
            self._ht_needs_recompute.wait() # wait until a new image is available
            tstart = time.time()
            self._ht_needs_recompute.clear()
            self._updateHistogram()
            tend = time.time()

            # sleep at as much, to ensure we are not using too much CPU
            tsleep = max(0.2, tend - tstart) # max 5 Hz
            time.sleep(tsleep)

    def onNewImage(self, dataflow, data):
        # For now, raw images are pretty simple: we only have one
        # (in the future, we could keep the old ones which are not fully
        # overlapped)

        old_irange = self._irange
        if not self.raw:
            self.raw.append(data)
            old_irange = None # will force histogram creation
        else:
            self.raw[0] = data

        # Depth can change at each image (depends on hardware settings)
        self._updateIRange()
        if old_irange != self._irange:
            logging.debug("Updating irange to %s", self._irange)
            # This ensures there's always a valid histogram
            self._updateHistogram()
        else:
            self._shouldUpdateHistogram()

        self._updateImage()


class SEMStream(Stream):
    """ Stream containing images obtained via Scanning electron microscope.

    It basically knows how to activate the scanning electron and the detector.
    """
    def __init__(self, name, detector, dataflow, emitter):
        Stream.__init__(self, name, detector, dataflow, emitter)

        # TODO: drift correction
        # .driftCorrection: Boolean
        # .driftROI: the region used for the drift correction
        # .driftCorrectionPeriod: time in s between each correction (approximate
        #   ,tries to do it after every N lines, or every N pixels)
        # Need to see

        # TODO: Anti-aliasing/Pixel fuzzing
        # .fuzzing: boolean
        # Might be better to automatically activate it for Spectrum, and disable
        # it for AR (without asking the user)

        try:
            self._prevDwellTime = emitter.dwellTime.value
            emitter.dwellTime.subscribe(self.onDwellTime)
        except AttributeError:
            # if emitter has no dwell time -> no problem
            pass

        # Actually use the ROI
        self.roi.subscribe(self._onROI)

        # Spot mode: when set (and stream is active), it will drive the e-beam
        # do only the center of the scanning area. Image is not updated.
        # TODO: is this the right interface? Shall we just have a different
        # stream type?
        self.spot = model.BooleanVA(False)
        # used to reset the previous settings after spot mode
        self._no_spot_settings = (None, None, None) # dwell time, resolution, translation
        self.spot.subscribe(self._onSpot)

    def _onROI(self, roi):
        """
        Update the scanning area of the SEM according to the roi
        """
        # only change hw settings if stream is active (and not spot mode)
        # Note: we could also (un)subscribe whenever these changes, but it's
        # simple like this.
        if not self.is_active.value or self.spot.value:
            return

        # FIXME: this is fighting against the resolution setting of the SEM
        # => only apply if is_active (and not spot mode...)
        # We should remove res setting from the GUI when this ROI is used.
        center = ((roi[0] + roi[2]) / 2, (roi[1] + roi[3]) / 2)
        width = (roi[2] - roi[0], roi[3] - roi[1])

        shape = self._emitter.shape
        # translation is distance from center (situated at 0.5, 0.5), can be floats
        trans = (shape[0] * (center[0] - 0.5), shape[1] * (center[1] - 0.5))
        # resolution is the maximum resolution at the scale in proportion of the width
        scale = self._emitter.scale.value
        res = (max(1, int(round(shape[0] * width[0] / scale[0]))),
               max(1, int(round(shape[1] * width[1] / scale[1]))))

        # always in this order
        self._emitter.resolution.value = res
        self._emitter.translation.value = trans

    def _onSpot(self, active):
        if active:
            self._startSpot()
        else:
            self._stopSpot()

    def _startSpot(self):
        """
        Start the spot mode. Can handle being called if it's already active
        """
        if self._no_spot_settings != (None, None, None):
            logging.debug("Starting spot mode while it was already active")
            return

        # to be avoid potential weird scanning while changing values
        self._dataflow.unsubscribe(self.onNewImage)

        logging.debug("Activating spot mode")
        self._no_spot_settings = (self._emitter.dwellTime.value,
                                  self._emitter.resolution.value,
                                  self._emitter.translation.value)

        # resolution -> translation: order matters
        self._emitter.resolution.value = (1, 1)
        self._emitter.translation.value = (0, 0) # position of the spot (floats)

        # put a not too short dwell time to avoid acquisition to keep repeating,
        # and not too long to avoid using too much memory for acquiring one point.
        self._emitter.dwellTime.value = 0.1 # s

        if self.is_active.value:
            self._dataflow.subscribe(self.onNewImage)

    def _stopSpot(self):
        """
        Stop the spot mode. Can handle being called if it's already inactive
        """
        if self._no_spot_settings == (None, None, None):
            logging.debug("Stop spot mode while it was already inactive")
            return

        # to be avoid potential weird scanning while changing values
        self._dataflow.unsubscribe(self.onNewImage)

        logging.debug("Disabling spot mode")

        (self._emitter.dwellTime.value,
         self._emitter.resolution.value,
         self._emitter.translation.value) = self._no_spot_settings

        self._no_spot_settings = (None, None, None)

        if self.is_active.value:
            self._dataflow.subscribe(self.onNewImage)

    def estimateAcquisitionTime(self):

        try:
            res = list(self._emitter.resolution.value)
            # Typically there is few more pixels inserted at the beginning of
            # each line for the settle time of the beam. We guesstimate by just
            # adding 1 pixel to each line
            if len(res) == 2:
                res[1] += 1
            else:
                logging.warning(("Resolution of scanner is not 2 dimensional, "
                                 "time estimation might be wrong"))
            # Each pixel x the dwell time in seconds
            duration = self._emitter.dwellTime.value * numpy.prod(res)
            # Add the setup time
            duration += self.SETUP_OVERHEAD

            return duration
        # TODO: Remove 'catch-all' with realistic exception
        except Exception:  #pylint: disable=W0703
            msg = "Exception while estimating acquisition time of %s"
            logging.exception(msg, self.name.value)
            return Stream.estimateAcquisitionTime(self)

    def onActive(self, active):
        if active:
            # TODO: if can blank => unblank

            # update hw settings to our own ROI
            self._onROI(self.roi.value)

        # handle spot mode
        if self.spot.value:
            if active:
                self._startSpot()
            else:
                self._stopSpot()
        super(SEMStream, self).onActive(active)

    def onDwellTime(self, value):
        # When the dwell time changes, the new value is only used on the next
        # acquisition. Assuming the change comes from the user (very likely),
        # then if the current acquisition would take a long time, cancel it, and
        # restart acquisition so that the new value is directly used. The main
        # goal is to avoid cases where user mistakenly put a 10+ s acquisition,
        # and it takes ages to get back to a faster acquisition. Note: it only
        # works if we are the only subscriber (but that's very likely).

        try:
            if self.is_active.value == False:
                # not acquiring => nothing to do
                return

            # approximate time for the current image acquisition
            res = self._emitter.resolution.value
            prevDuration = self._prevDwellTime * numpy.prod(res)

            if prevDuration < 1:
                # very short anyway, not worthy
                return

            # TODO: do this on a rate-limited fashion (now, or ~1s)
            # unsubscribe, and re-subscribe immediately
            self._dataflow.unsubscribe(self.onNewImage)
            self._dataflow.subscribe(self.onNewImage)

        finally:
            self._prevDwellTime = value

    def onNewImage(self, df, data):
        """

        """
        # In spot mode, don't update the image.
        # (still receives data as the e-beam needs an active detector to scan)
        if self.spot.value:
            return
        super(SEMStream, self).onNewImage(df, data)


    # TODO: should be common to all Stream classes
    def getStatic(self):
        """
        return (StaticSEMStream): similar stream, but static
        """
        ss = StaticSEMStream(self.name.value, self.raw[0])
        return ss

class CameraStream(Stream):
    """ Abstract class representing streams which have a digital camera as a
    detector.

    Mostly used to share time estimation only.
    """
    def estimateAcquisitionTime(self):
        # exposure time + readout time * pixels (if CCD) + set-up time
        try:
            exp = self._detector.exposureTime.value
            res = self._detector.resolution.value
            if isinstance(self._detector.readoutRate,
                          model.VigilantAttributeBase):
                readout = 1 / self._detector.readoutRate.value
            else:
                # let's assume it's super fast
                readout = 0

            duration = exp + numpy.prod(res) * readout + self.SETUP_OVERHEAD
            return duration
        except:
            msg = "Exception while estimating acquisition time of %s"
            logging.exception(msg, self.name.value)
            return Stream.estimateAcquisitionTime(self)

    def _stop_light(self):
        """
        Ensures the light is turned off (temporarily)
        """
        # Just change the intensity of each wavelengths, so that the power is
        # recorded.
        emissions = [0] * len(self._emitter.emissions.value)
        self._emitter.emissions.value = emissions

        # TODO: might need to be more clever to avoid turning off and on the
        # light source when just switching between FluoStreams. => have a
        # global acquisition manager which takes care of switching on/off
        # the emitters which are used/unused.


class BrightfieldStream(CameraStream):
    """ Stream containing images obtained via optical brightfield illumination.

    It basically knows how to select white light and disable any filter.
    """

    def onActive(self, active):
        if active:
            self._setup_excitation()
            # TODO: do we need to have a special command to disable filter??
            # or should it be disabled automatically by the other streams not
            #using it?
            # self._setup_emission()
        else:
            self._stop_light()
        Stream.onActive(self, active)

    # def _setup_emission(self):
    #     if not self._filter.band.readonly:
    #         raise NotImplementedError("Do not know how to change filter band")

    def _setup_excitation(self):
        # TODO: how to select white light??? We need a brightlight hardware?
        # Turn on all the sources? Does this always mean white?
        # At least we should set a warning if the final emission range is quite
        # different from the normal white spectrum
        em = [1] * len(self._emitter.emissions.value)
        self._emitter.emissions.value = em

class CameraNoLightStream(CameraStream):
    """ Stream containing images obtained via optical CCD but without any light
     source on. Used for the SECOM lens alignment tab.

    It basically knows how to turn off light and remove position information.
    """
    def __init__(self, name, detector, dataflow, emitter, position=None):
        """
        position (VA of dict str -> float): stage position to use instead of the
         position contained in the metadata.
        """
        self._position = position
        CameraStream.__init__(self, name, detector, dataflow, emitter)
        self._prev_light_power = self._emitter.power.value

    def onActive(self, active):
        # TODO: use _stop_light()
        if active:
            # turn off the light
            self._prev_light_power = self._emitter.power.value
            self._emitter.power.value = 0
        else:
            # restore the light
            # TODO: not necessary if each stream had its own hardware settings
            self._emitter.power.value = self._prev_light_power
        Stream.onActive(self, active)

    def _findPos(self, data):
        if self._position:
            pos = self._position.value # a stage should always have x,y axes
            return (pos["x"], pos["y"])
        else:
            return super(CameraNoLightStream, self)._findPos(data)

class FluoStream(CameraStream):
    """ Stream containing images obtained via epifluorescence.

    It basically knows how to select the right emission/filtered wavelengths,
    and how to taint the image.

    Note: Excitation is (filtered) light coming from a light source and
    emission is the light emitted by the sample.
    """

    def __init__(self, name, detector, dataflow, emitter, em_filter):
        """
        name (string): user-friendly name of this stream
        detector (Detector): the detector which has the dataflow
        dataflow (Dataflow): the dataflow from which to get the data
        emitter (Light): the HwComponent to modify the light excitation
        filter (Filter): the HwComponent to modify the emission light filtering
        """
        CameraStream.__init__(self, name, detector, dataflow, emitter)
        self._em_filter = em_filter

        # TODO: instead of defining the excitation and emission wavelengths,
        # just give the user the same choice as the hardware, and the user
        # has to pick the right value (and the GUI can start with an
        # "informed guess").

        # This is what is displayed to the user
        # Default to the center of the first excitation and emission bands
        exc_range = [min([s[0] for s in emitter.spectra.value]),
                     max([s[4] for s in emitter.spectra.value])]
        self.excitation = model.FloatContinuous(emitter.spectra.value[0][2],
                                                range=exc_range, unit="m")
        self.excitation.subscribe(self.onExcitation)

        # The wavelength band on the out path (set when emission changes)
        bands = em_filter.axes["band"].choices
        cur_pos = em_filter.position.value["band"]
        self._current_out_wl = bands[cur_pos]
        em_range = self._find_emission_range(bands.values())
        self.emission = model.FloatContinuous(em_range[0] + 1e-9,
                                              range=em_range, unit="m")
        self.emission.subscribe(self.onEmission)

        # colouration of the image
        default_tint = conversion.wave2rgb(self.emission.value)
        self.tint = model.ListVA(default_tint, unit="RGB") # 3-tuple R,G,B
        self.tint.subscribe(self.onTint)

    def onActive(self, active):
        if active:
            self._setup_excitation()
            self._setup_emission()
        else:
            self._stop_light() # important if SEM image to be acquired
        Stream.onActive(self, active)

    def _updateImage(self): #pylint: disable=W0221
        Stream._updateImage(self, self.tint.value)

    def onExcitation(self, value):
        if self.is_active.value:
            self._setup_excitation()

    def onEmission(self, value):
        if self.is_active.value:
            self._setup_emission()

    def onTint(self, value):
        if self.raw:
            data = self.raw[0]
            data.metadata[model.MD_USER_TINT] = value

        self._updateImage()

    def _find_emission_range(self, bands):
        """
        return (float, float): min/max wavelength
        """
        lows, highs = [], []
        # if multi-band: get the range of all
        for b in bands:
            if isinstance(b[0], collections.Iterable):
                rng = self._find_emission_range(b)
            else:
                rng = b
            lows.append(rng[0])
            highs.append(rng[1])

        return min(lows), max(highs)

    def _find_best_emission_band(self, wl):
        """
        wl (float): wavelength (in m)
        return (int): the position corresponding to the best band
        """
        # The most fitting band: narrowest band centered around the wavelength
        bands = self._em_filter.axes["band"].choices
        def quantify_fit(wl, band):
            """ Quantifies how well the given wavelength matches the given
            band: the better the match, the higher the return value will be.
            wl (float): Wavelength to quantify
            band ((list of) 2-tuple floats): The band(s)
            return (0<float): the more, the merrier
            """
            # if multi-band: get the best of all
            if isinstance(band[0], collections.Iterable):
                return max(quantify_fit(wl, b) for b in band)

            if band[0] < wl < band[1]:
                distance = abs(wl - numpy.mean(band)) # distance to center
                width = band[1] - band[0]
                # ensure it cannot get infinite score for being in the center
                return 1 / (max(distance, 1e-9) * max(width, 1e-9))
            elif band[0] - 20e-9 < wl < band[1] + 20e-9:
                # almost? => 100x less good
                distance = abs(wl - numpy.mean(band)) # distance to center
                width = band[1] - band[0]
                return 0.01 / (max(distance, 1e-9) * max(width, 1e-9))
            else:
                # No match
                return 0

        scores = dict((k, quantify_fit(wl, v)) for k, v in bands.items())
        # key with best score
        best, score = max(scores.items(), key=lambda x: x[1])
        if score == 0:
            return None
        return best

    def _setup_emission(self):
        """
        Set-up the hardware for the right emission light (light path between
        the sample and the CCD), and check whether the emission value matches
        the emission filter bands.
        """
        wl = self.emission.value

        p = self._find_best_emission_band(wl)
        self._removeWarnings(Stream.WARNING_EMISSION_IMPOSSIBLE,
                             Stream.WARNING_EMISSION_NOT_OPT)
        if p is not None:
            f = self._em_filter.moveAbs({"band": p})
            band = self._em_filter.axes["band"].choices[p]
            self._current_out_wl = band

            # Detect if the selected band is outside of wl
            for l, h in band:
                if l < wl < h:
                    break
            else:
                self._addWarning(Stream.WARNING_EMISSION_NOT_OPT)
                # TODO: add the actual band in the warning message?

            f.result() # wait for the move to be finished
        else:
            logging.warning("Emission wavelength %s doesn't fit the filter",
                            units.readable_str(wl, "m"))
            self._addWarning(Stream.WARNING_EMISSION_IMPOSSIBLE)
            
        return

    def _setup_excitation(self):
        """ Set-up the excitation light to the specified wavelength (light path
        between the light source and the sample), and check whether this
        actually can work.
        """
        wave_length = self.excitation.value

        def quantify_fit(wl, spec):
            """ Quantifies how well the given wavelength matches the given
            spectrum: the better the match, the higher the return value will be.
            wl (float): Wavelength to quantify
            spec (5-tuple float): The spectrum to check the wavelength against
            return (0<float): the more, the merrier
            """
            if spec[0] < wl < spec[4]:
                distance = abs(wl - spec[2]) # distance to 100%
                if distance:
                    return 1 / distance
                # No distance, ultimate match
                return float("inf")
            else:
                # No match
                return 0

        spectra = self._emitter.spectra.value
        # arg_max with quantify_fit function as key
        best = max(spectra, key=lambda x: quantify_fit(wave_length, x))
        i = spectra.index(best)

        # create an emissions with only one source active, which best matches
        # the excitation wavelength
        emissions = [0] * len(spectra)
        emissions[i] = 1
        self._emitter.emissions.value = emissions

        # TODO: read back self._emitter.emissions.value to get the actual value
        # set warnings if necessary
        self._removeWarnings(Stream.WARNING_EXCITATION_IMPOSSIBLE,
                             Stream.WARNING_EXCITATION_NOT_OPT)

        # TODO: if the band is too wide (e.g., white), it should also have a
        # warning
        # TODO: if the light can only be changed manually, display a warning
        if wave_length < best[0] or wave_length > best[4]:
            # outside of band
            self._addWarning(Stream.WARNING_EXCITATION_IMPOSSIBLE)
        elif wave_length < best[1] or wave_length > best[3]:
            # outside of main 50% band
            self._addWarning(Stream.WARNING_EXCITATION_NOT_OPT)

    def onNewImage(self, dataflow, data):
        # Add some metadata on the fluorescence

        # TODO: handle better if there is already MD_OUT_WL
        data.metadata[model.MD_OUT_WL] = self._current_out_wl

        data.metadata[model.MD_USER_TINT] = self.tint.value
        super(FluoStream, self).onNewImage(dataflow, data)


class RepetitionStream(Stream):
    """
    Abstract class for streams which are actually a set multiple acquisition
    repeated over a grid.
    """

    def __init__(self, name, detector, dataflow, emitter):
        self.name = model.StringVA(name)

        # Hardware Components
        self._detector = detector # the spectrometer
        self._emitter = emitter # the e-beam
        # To acquire simultaneously other detector (ex: SEM secondary electrons)
        # a separate stream must be used, and the acquisition manager will take
        # care of doing both at the same time

        # data-flow of the spectrometer
        self._dataflow = dataflow

        self.raw = [] # to contain data during acquisition (from MD streams)

        # all the information needed to acquire an image (in addition to the
        # hardware component settings which can be directly set).

        # ROI + repetition is sufficient, but pixel size is nicer for the user
        # and allow us to ensure each pixel is square. (Non-square pixels are
        # not a problem for the hardware, but annoying to display data in normal
        # software).

        # We ensure in the setters that all the data is always consistent:
        # roi set: roi + pxs â repetition + roi + pxs
        # pxs set: roi + pxs â repetition + roi (small changes)
        # repetition set: repetition + roi + pxs â repetition + pxs + roi (small changes)

        # Region of interest as left, top, right, bottom (in ratio from the
        # whole area of the emitter => between 0 and 1)
        self.roi = model.TupleContinuous((0, 0, 1, 1),
                                         range=[(0, 0, 0, 0), (1, 1, 1, 1)],
                                         cls=(int, long, float),
                                         setter=self._setROI)
        # the number of pixels acquired in each dimension
        # it will be assigned to the resolution of the emitter (but cannot be
        # directly set, as one might want to use the emitter while configuring
        # the stream).
        self.repetition = model.ResolutionVA(emitter.resolution.value,
                                             emitter.resolution.range,
                                             setter=self._setRepetition)

        # the size of the pixel, horizontally and vertically
        # actual range is dynamic, as it changes with the magnification
        self.pixelSize = model.FloatContinuous(emitter.pixelSize.value[0],
                           range=[0, 1], unit="m", setter=self._setPixelSize)

        # exposure time of each pixel is the exposure time of the detector,
        # the dwell time of the emitter will be adapted before acquisition.

        # Update the pixel size whenever SEM magnification changes
        # This allows to keep the ROI at the same place in the SEM FoV.
        # Note: this is to be done only if the user needs to manually update the
        # magnification.
        self._prev_mag = emitter.magnification.value
        emitter.magnification.subscribe(self._onMagnification)

    def _onMagnification(self, mag):
        """
        Called when the SEM magnification is updated
        """
        # Update the pixel size so that the ROI stays that the same place in the
        # SEM FoV and with the same repetition.
        # The bigger is the magnification, the smaller should be the pixel size
        ratio = self._prev_mag / mag
        self.pixelSize._value *= ratio
        self.pixelSize.notify(self.pixelSize._value)

    def _updateROIAndPixelSize(self, roi, pxs):
        """
        roi : ROI wanted (might be slightly changed)
        pxs (float): new pixel size (must be within allowed range, always respected)
        Returns new ROI and repetition
        """
        # If ROI is undefined => everything is fine
        if roi == UNDEFINED_ROI:
            return roi, self.repetition.value

        epxs = self.emitter.pixelSize.value
        eshape = self.emitter.shape
        phy_size = [epxs[0] * eshape[0], epxs[1] * eshape[1]] # max physical ROI

        # maximum repetition: either depends on minimum pxs or maximum roi
        roi_size = [roi[2] - roi[0], roi[3] - roi[1]]
        max_rep = [max(1, min(int(eshape[0] * roi_size[0]), int(phy_size[0] / pxs))),
                   max(1, min(int(eshape[1] * roi_size[1]), int(phy_size[1] / pxs)))]

        # compute the repetition (ints) that fits the ROI with the pixel size
        rep = [round(phy_size[0] * roi_size[0] / pxs),
               round(phy_size[1] * roi_size[1] / pxs)]
        rep = [int(max(1, min(rep[0], max_rep[0]))),
               int(max(1, min(rep[1], max_rep[1])))]

        # update the ROI so that it's _exactly_ pixel size * repetition,
        # while keeping its center fixed
        roi_center = [(roi[0] + roi[2]) / 2,
                      (roi[1] + roi[3]) / 2]
        roi_size = [rep[0] * pxs / phy_size[0],
                    rep[1] * pxs / phy_size[1]]
        roi = [roi_center[0] - roi_size[0] / 2,
               roi_center[1] - roi_size[1] / 2,
               roi_center[0] + roi_size[0] / 2,
               roi_center[1] + roi_size[1] / 2]

        # shift the ROI if it's now slightly outside the possible area
        if roi[0] < 0:
            roi[2] = min(1, roi[2] - roi[0])
            roi[0] = 0
        elif roi[2] > 1:
            roi[0] = max(0, roi[0] - (roi[2] - 1))
            roi[2] = 1

        if roi[1] < 0:
            roi[3] = min(1, roi[3] - roi[1])
            roi[1] = 0
        elif roi[3] > 1:
            roi[1] = max(0, roi[1] - (roi[3] - 1))
            roi[3] = 1

        return tuple(roi), tuple(rep)

    def _setROI(self, roi):
        """
        Ensures that the ROI is always an exact number of pixels, and update
         repetition to be the correct number of pixels
        roi (tuple of 4 floats)
        returns (tuple of 4 floats): new ROI
        """
        # If only width or height changes, ensure we respect it by
        # adapting pixel size to be a multiple of the new size
        pxs = self.pixelSize.value

        old_roi = self.roi.value
        if old_roi != UNDEFINED_ROI and roi != UNDEFINED_ROI:
            old_size = (old_roi[2] - old_roi[0], old_roi[3] - old_roi[1])
            new_size = (roi[2] - roi[0], roi[3] - roi[1])
            if abs(old_size[0] - new_size[0]) < 1e-6:
                dim = 1
                # If dim 1 is also equal -> new pixel size will not change
            elif abs(old_size[1] - new_size[1]) < 1e-6:
                dim = 0
            else:
                dim = None

            if dim is not None:
                old_rep = self.repetition.value[dim]
                new_phy_size = old_rep * pxs * new_size[dim] / old_size[dim]
                new_rep_flt = new_phy_size / pxs
                new_rep_int = max(1, round(new_rep_flt))
                pxs *= new_rep_flt / new_rep_int
                pxs_range = self._getPixelSizeRange()
                pxs = max(pxs_range[0], min(pxs, pxs_range[1]))

        roi, rep = self._updateROIAndPixelSize(roi, pxs)
        # update repetition without going through the checks
        self.repetition._value = rep
        self.repetition.notify(rep)
        self.pixelSize._value = pxs
        self.pixelSize.notify(pxs)

        return roi

    def _setPixelSize(self, pxs):
        """
        Ensures pixel size is within the current allowed range, and updates
         ROI and repetition.
        return (float): new pixel size
        """
        # clamp
        pxs_range = self._getPixelSizeRange()
        pxs = max(pxs_range[0], min(pxs, pxs_range[1]))
        roi, rep = self._updateROIAndPixelSize(self.roi.value, pxs)

        # update roi and rep without going through the checks
        self.roi._value = roi
        self.roi.notify(roi)
        self.repetition._value = rep
        self.repetition.notify(rep)

        return pxs

    def _setRepetition(self, repetition):
        """
        Find a fitting repetition and update pixel size and ROI, using the
         current ROI making sure that the repetition is ints (pixelSize and roi
        changes are notified but the setter is not called).
        repetition (tuple of 2 ints): new repetition wanted (might be clamped)
        returns (tuple of 2 ints): new (valid) repetition
        """
        roi = self.roi.value
        # If ROI is undefined => everything is fine
        if roi == UNDEFINED_ROI:
            return repetition

        prev_rep = self.repetition.value
        epxs = self.emitter.pixelSize.value
        eshape = self.emitter.shape

        # The basic principle is that the ROI stays the same, and the pixel size
        # is modified to fit the repetition. So it's basically an indirect way
        # to change the pixel size.

        # clamp horizontal repetition to be sure it's correct
        roi_size = [roi[2] - roi[0], roi[3] - roi[1]]
        max_rep = [max(1, math.ceil(eshape[0] * roi_size[0])),
                   max(1, math.ceil(eshape[1] * roi_size[1]))]

        repetition = [min(repetition[0], max_rep[0]),
                      min(repetition[1], max_rep[1])]

        # update the pixel size according to horizontal or vertical repetition,
        # depending on what the user "asked" (changed)
        if prev_rep[0] == repetition[0]:
            # TODO: move the computations inside
            pxs = (epxs[1] * eshape[1] * roi_size[1]) / repetition[1]
        elif prev_rep[1] == repetition[1]:
            pxs = (epxs[0] * eshape[0] * roi_size[0]) / repetition[0]
        else:
            # the whole repetition changed => keep area and adapt ROI
            roi_center = [(roi[0] + roi[2]) / 2, (roi[1] + roi[3]) / 2]
            area_ratio = math.sqrt(numpy.prod(prev_rep) / numpy.prod(repetition))
            rel_pxs = roi_size[0] / prev_rep[0] #, roi_size[1] / prev_rep[1])
            roi_size = [area_ratio * rel_pxs * repetition[0],
                        area_ratio * rel_pxs * repetition[1]]
            roi = [roi_center[0] - roi_size[0] / 2,
                   roi_center[1] - roi_size[1] / 2,
                   roi_center[0] + roi_size[0] / 2,
                   roi_center[1] + roi_size[1] / 2]
            pxs = self.pixelSize.value * area_ratio

        roi, rep = self._updateROIAndPixelSize(roi, pxs)
        # update roi and pixel size without going through the checks
        self.roi._value = roi
        self.roi.notify(roi)
        self.pixelSize._value = pxs
        self.pixelSize.notify(pxs)

        return rep

    def _getPixelSizeRange(self):
        """
        return (tuple of 2 floats): min and max value of the pixel size at the
          current magnification, in m.
        """
        # Two things to take care of:
        # * current pixel size of the emitter (which depends on the magnification)
        # * merge horizontal/vertical dimensions into one fits-all

        # The current emitter pixel size is the minimum size
        epxs = self.emitter.pixelSize.value
        min_pxs = max(epxs)
        shape = self.emitter.shape
        max_pxs = min(epxs[0] * shape[0], epxs[1] * shape[1])
        return (min_pxs, max_pxs)

    def estimateAcquisitionTime(self):
        try:
            rep = list(self.repetition.value)
            # Typically there is few more pixels inserted at the beginning of
            # each line for the settle time of the beam. We guesstimate by just
            # adding 1 pixel to each line
            if len(rep) >= 2 and numpy.prod(rep[1:]) > 1:
                rep[1] += 1

            # Each pixel x the exposure time (of the detector) + readout time +
            # 20% overhead
            try:
                ro_rate = self._detector.readoutRate.value
                res = self._detector.resolution.value
                readout = numpy.prod(res) / ro_rate + 0.06
            except Exception:
                readout = 0.06
            exp = self._detector.exposureTime.value
            duration = numpy.prod(rep) * (exp + readout) * 1.20
            # Add the setup time
            duration += self.SETUP_OVERHEAD

            return duration
        except Exception:
            msg = "Exception while estimating acquisition time of %s"
            logging.exception(msg, self.name.value)
            return Stream.estimateAcquisitionTime(self)

class SpectrumStream(RepetitionStream):
    """ A Spectrum stream.

    Be aware that acquisition can be very long so should not be used for live
    view. So it has no .image (for now). See StaticSpectrumStream for displaying
    a stream.
    """
    def __init__(self, name, detector, dataflow, emitter):
        RepetitionStream.__init__(self, name, detector, dataflow, emitter)
        # For SPARC: typical user wants density a bit lower than SEM
        self.pixelSize.value *= 6

    def getStatic(self):
        """
        return (StaticSpectrumStream): similar stream, but static
        """
        raise NotImplementedError("Stream doesn't actually acquire data")

class ARStream(RepetitionStream):
    """
    An angular-resolved stream, for a set of points (on the SEM).
    Be aware that acquisition can be very long so
    should not be used for live view. So it has no .image (for now).
    See StaticARStream for displaying a stream, and CameraStream for displaying
    just the current AR view.
    """
    def __init__(self, name, detector, dataflow, emitter):
        RepetitionStream.__init__(self, name, detector, dataflow, emitter)
        # For SPARC: typical user wants density much lower than SEM
        self.pixelSize.value *= 30

    def getStatic(self):
        """
        return (StaticARStream): similar stream, but static
        """
        raise NotImplementedError("Stream doesn't actually acquire data")

class StaticStream(Stream):
    """ Stream containing one static image.

    For testing and static images.
    """

    def __init__(self, name, image):
        """
        Note: parameters are different from the base class.
        image (InstrumentalImage or DataArray of shape (111)YX): image to
          display or raw data.
          If it is a DataArray, the metadata should contain at least MD_POS and
          MD_PIXEL_SIZE.
        """
        Stream.__init__(self, name, None, None, None)
        if isinstance(image, InstrumentalImage):
            # TODO: use original image as raw, to allow changing the B/C/tint
            # Need to distinguish between greyscale (possible) and colour (impossible)
            self.image = VigilantAttribute(image)
        else: # raw data
            # Check it's 2D
            if len(image.shape) < 2:
                raise ValueError("Data must be 2D")
            # make it 2D by removing first dimensions (which must 1)
            if len(image.shape) > 2:
                l1d = len(image.shape) - 2
                if image.shape[:l1d] != (1,) * l1d: # must look like (1,1,1)
                    raise ValueError("Data must be 2D but has shape %s" %
                                     (image.shape,))
                image = image[(0,) * l1d]

            self.onNewImage(None, image)

    def onActive(self, active):
        # don't do anything
        pass

class StaticSEMStream(StaticStream):
    """
    Same as a StaticStream, but considered a SEM stream
    """
    pass

class StaticBrightfieldStream(StaticStream):
    """
    Same as a StaticStream, but considered a Brightfield stream
    """
    pass

class StaticFluoStream(StaticStream):
    """Static Stream containing images obtained via epifluorescence.

    It basically knows how to show the emission/filtered wavelengths,
    and how to taint the image.
    """

    def __init__(self, name, image):
        """
        Note: parameters are different from the base class.
        image (DataArray of shape (111)YX): raw data. The metadata should
          contain at least MD_POS and MD_PIXEL_SIZE. It should also contain
          MD_IN_WL and MD_OUT_WL.
        """
        # Wavelengths
        try:
            exc_range = image.metadata[model.MD_IN_WL]
            val = numpy.mean(exc_range)
            self.excitation = model.FloatContinuous(val,
                                                    range=exc_range,
                                                    unit="m",
                                                    readonly=True)
        except KeyError:
            logging.warning("No excitation wavelength for fluorescence stream")

        try:
            em_range = image.metadata[model.MD_OUT_WL]
            val = numpy.mean(em_range)
            self.emission = model.FloatContinuous(val,
                                                  range=em_range,
                                                  unit="m",
                                                  readonly=True)

            default_tint = conversion.wave2rgb(self.emission.value)
        except KeyError:
            logging.warning("No emission wavelength for fluorescence stream")
            default_tint = (0, 255, 0) # green is most typical

        # colouration of the image
        tint = image.metadata.get(model.MD_USER_TINT, default_tint)
        self.tint = model.ListVA(tint, unit="RGB") # 3-tuple R,G,B
        self.tint.subscribe(self.onTint)

        # Do it at the end, as it forces it the update of the image
        StaticStream.__init__(self, name, image)

    def _updateImage(self): #pylint: disable=W0221
        Stream._updateImage(self, self.tint.value)

    def onTint(self, value):
        self._updateImage()


class StaticARStream(StaticStream):
    """
    A angular resolved stream for one set of data.

    There is no directly nice (=obvious) format to store AR data.
    The difficulty is that data is somehow 4 dimensions: SEM-X, SEM-Y, CCD-X,
    CCD-Y. CCD-dimensions do not correspond directly to quantities, until
    converted into angle/angle (knowing the position of the pole).
    As it's possible that positions on the SEM are relatively random, and it
    is convenient to have a simple format when only one SEM pixel is scanned,
    we've picked the following convention:
     * each CCD image is a separate DataArray
     * each CCD image contains metadata about the SEM position (MD_POS, in m)
       pole (MD_AR_POLE, in px), and acquisition time (MD_ACQ_DATE)
     * multiple CCD images are grouped together in a list
    """
    def __init__(self, name, data):
        """
        name (string)
        data (model.DataArray of shape (YX) or list of such DataArray). The
         metadata MD_POS and MD_AR_POLE should be provided
        """
        Stream.__init__(self, name, None, None, None)

        if isinstance(data, InstrumentalImage):
            raise NotImplementedError("ARStream needs a list of raw data")
        elif not isinstance(data, collections.Iterable):
            data = [data] # from now it's just a list of DataArray

        # find positions of each acquisition
        # tuple of 2 floats -> DataArray: position on SEM -> data
        self._sempos = {}
        for d in data:
            try:
                self._sempos[d.metadata[MD_POS]] = img.ensure2DImage(d)
            except KeyError:
                logging.info("Skipping DataArray without known position")

        # Cached conversion of the CCD image to polar representation
        self._polar = {} # dict tuple 2 floats -> DataArray
        # TODO: automatically fill it a background thread

        self.raw = list(self._sempos.values())

        # SEM position displayed, (None, None) == no point selected
        self.point = model.VAEnumerated((None, None),
                     choices=frozenset([(None, None)] + list(self._sempos.keys())))
        self.point.subscribe(self._onPoint)

        if self._sempos:
            self.point.value = list(self._sempos.keys())[0]

    def _getPolarProjection(self, pos):
        """
        Return the polar projection of the image at the given position.
        pos (tuple of 2 floats): position (must be part of the ._sempos
        returns DataArray: the polar projection
        """
        if pos in self._polar:
            polarp = self._polar[pos]
        else:
            # Compute the polar representation
            data = self._sempos[pos]
            try:
                # TODO: First compute quickly a low resolution and then
                # compute a high resolution version.
                # TODO: could use the size of the canvas that will display
                # the image to save some computation time.

                # TODO: handle having a background image (i.e., same acquisition
                # but with e-beam blanked)
                # Remove the background value
                data0 = polar.ARBackgroundSubtract(data)

                # 2 x size of original image (on smallest axis) and at most
                # the size of a full-screen canvas
                size = min(min(data0.shape[-2:]) * 2, 1134)
                polarp = polar.AngleResolved2Polar(data0, size, hole=False)
                self._polar[pos] = polarp
            except Exception:
                logging.exception("Failed to convert to azymuthal projection")
                return data # display it raw as fallback

        return polarp

    @limit_invocation(0.1) # Max 10 Hz
    def _updateImage(self):
        """ Recomputes the image with all the raw data available for the current
        selected point.
        """
        # check to avoid running it if there is already one running
        if self._running_upd_img or not self.raw:
            return

        pos = self.point.value
        try:
            self._running_upd_img = True

            if pos == (None, None):
                self.image.value = InstrumentalImage(None)
            else:
                polar = self._getPolarProjection(pos)
                # update the histrogram
                # TODO: cache the histogram per image
                # FIXME: histogram should not include the black pixels outside
                # of the circle. => use a masked array?
                self._updateHistogram(polar)
                irange = self._getDisplayIRange()

                # Convert to RGB
                rgbim = img.DataArray2RGB(polar, irange)
                im = NDImage2wxImage(rgbim)
                im.InitAlpha()

                # TODO: Special InstrumentalImage for polar view, without MPP nor pos?
                self.image.value = InstrumentalImage(im, 0.001, (0, 0))
        except Exception:
            logging.exception("Updating %s image", self.__class__.__name__)
        finally:
            self._running_upd_img = False

    def _onPoint(self, pos):
        self._updateImage()


class StaticSpectrumStream(StaticStream):
    """
    A Spectrum stream which displays only one static image/data.
    The main difference from the normal streams is that the data is 3D (a cube)
    The metadata should have a MD_WL_POLYNOMIAL
    Note that the data received should be of the (numpy) shape CYX.
    When saving, the data will be converted to CTZYX (where TZ is 11)
    """
    def __init__(self, name, image):
        """
        name (string)
        image (model.DataArray of shape (CYX) or (C11YX)). The metadata
        MD_WL_POLYNOMIAL should be included in order to associate the C to a
        wavelength.
        """
        Stream.__init__(self, name, None, None, None)
        # Spectrum stream has in addition to normal stream:
        #  * information about the current bandwidth displayed (avg. spectrum)
        #  * coordinates of 1st point (1-point, line)
        #  * coordinates of 2nd point (line)

        if isinstance(image, InstrumentalImage):
            raise NotImplementedError("SpectrumStream needs a raw cube data")

        if len(image.shape) == 3:
            # force 5D
            image = image[:, numpy.newaxis, numpy.newaxis, :, :]
        elif len(image.shape) != 5 or image.shape[1:3] != (1, 1):
            logging.error("Cannot handle data of shape %s", image.shape)
            raise NotImplementedError("SpectrumStream needs a cube data")

        ### this is for "average spectrum" projection
        try:
            # cached list of wavelength for each pixel pos
            self._wl_px_values = self._get_wavelength_per_pixel(image)
        except (ValueError, KeyError):
            # useless polynomial => just show pixels values (ex: -50 -> +50 px)
            # TODO: try to make them always int?
            max_bw = image.shape[0] // 2
            min_bw = (max_bw - image.shape[0]) + 1
            self._wl_px_values = range(min_bw, max_bw + 1)
            assert(len(self._wl_px_values) == image.shape[0])
            unit_bw = "px"
            cwl = (max_bw + min_bw) // 2
            width = image.shape[0] // 12
        else:
            min_bw, max_bw = self._wl_px_values[0], self._wl_px_values[-1]
            unit_bw = "m"
            cwl = (max_bw + min_bw) / 2
            width = (max_bw - min_bw) / 12

        # low/high values of the spectrum displayed
        self.spectrumBandwidth = model.TupleContinuous(
                                    (cwl - width, cwl + width),
                                    range=((min_bw, min_bw), (max_bw, max_bw)),
                                    unit=unit_bw,
                                    cls=(int, long, float))

        # Whether the (per bandwidth) display should be split intro 3 sub-bands
        # which are applied to RGB
        self.fitToRGB = model.BooleanVA(False)

        # TODO: min/max: tl and br points of the image in physical coordinates
        # TODO: also need the size of a point (and density?)
        #self.point1 = model.ResolutionVA(unit="m") # FIXME: float
        #self.point2 = model.ResolutionVA(unit="m") # FIXME: float

        self._irange = None
        self._updateIRange()

        # This attribute is used to keep track of any selected pixel within the
        # data for the display of a spectrum
        self.selected_pixel = model.TupleVA((None, None)) # int, int

        self.fitToRGB.subscribe(self.onFitToRGB)
        self.spectrumBandwidth.subscribe(self.onSpectrumBandwidth)

        self.onNewImage(None, image) # generates the first rgb image

    def _get_wavelength_per_pixel(self, da):
        """
        Computes the wavelength for each pixel along the C dimension
        da (model.DataArray of shape C...): the DataArray with metadata either
          MD_WL_POLYNOMIAL or MD_WL_LIST
        return (list of float of length C): the wavelength (in m) for each pixel
         in C
        raises:
            KeyError: if no metadata is available
            ValueError: if the metadata doesn't provide enough information
        """
        # MD_WL_LIST has priority
        if model.MD_WL_LIST in da.metadata:
            wl = da.metadata[model.MD_WL_LIST]
            if len(wl) == da.shape[0]:
                return wl
            else:
                logging.warning("MD_WL_LIST is not the same length as the data")

        if MD_WL_POLYNOMIAL in da.metadata:
            pn = da.metadata[MD_WL_POLYNOMIAL]
            pn = polynomial.polytrim(pn)
            if len(pn) >= 2:
                npn = polynomial.Polynomial(pn,  #pylint: disable=E1101
                                            domain=[0, da.shape[0] - 1],
                                            window=[0, da.shape[0] - 1])
                return npn.linspace(da.shape[0])[1]
            else:
                # a polynomial or 0 or 1 value is useless
                raise ValueError("Wavelength polynomial has only %d degree"
                                 % len(pn))

        raise KeyError("No MD_WL_* metadata available")

    def _get_bandwidth_in_pixel(self):
        """
        Return the current bandwidth in pixels index
        returns (2-tuple of int): low and high pixel coordinates (included)
        """
        low, high = self.spectrumBandwidth.value

        # Find the closest pixel position for the requested wavelength
        low_px = numpy.searchsorted(self._wl_px_values, low, side="left")
        low_px = min(low_px, len(self._wl_px_values) - 1) # make sure it fits
        # TODO: might need better handling to show just one pixel (in case it's
        # useful) as in almost all cases, it will end up displaying 2 pixels at
        # least
        if high == low:
            high_px = low_px
        else:
            high_px = numpy.searchsorted(self._wl_px_values, high, side="right")
            high_px = min(high_px, len(self._wl_px_values) - 1)

        logging.debug("Showing between %g -> %g nm = %d -> %d px",
                      low * 1e9, high * 1e9, low_px, high_px)
        assert low_px <= high_px
        return low_px, high_px

    def _updateImageAverage(self, data):
        if self.auto_bc.value:
            # The histogram might be slightly old, but not too much
            irange = img.findOptimalRange(self.histogram._full_hist,
                                          self.histogram._edges,
                                          self.auto_bc_outliers.value / 100)

            # Also update the intensityRanges if auto BC
            edges = self.histogram._edges
            rrange = [(v - edges[0]) / (edges[1] - edges[0]) for v in irange]
            self.intensityRange.value = tuple(rrange)
        else:
            # just convert from the user-defined (as ratio) to actual values
            rrange = sorted(self.intensityRange.value)
            edges = self.histogram._edges
            irange = [edges[0] + (edges[1] - edges[0]) * v for v in rrange]

        # pick only the data inside the bandwidth
        spec_range = self._get_bandwidth_in_pixel()
        logging.debug("Spectrum range picked: %s px", spec_range)

        if not self.fitToRGB.value:
            # TODO: use better intermediary type if possible?, cf semcomedi
            av_data = numpy.mean(data[spec_range[0]:spec_range[1] + 1], axis=0)
            rgbim = img.DataArray2RGB(av_data, irange)
        else:
            # Note: For now this method uses three independant bands. To give
            # a better sense of continum, and be closer to reality when using
            # the visible light's band, we should take a weighted average of the
            # whole spectrum for each band.

            # divide the range into 3 sub-ranges of almost the same length
            len_rng = spec_range[1] - spec_range[0] + 1
            rrange = [spec_range[0], int(round(spec_range[0] + len_rng / 3)) - 1]
            grange = [rrange[1] + 1, int(round(spec_range[0] + 2 * len_rng / 3)) - 1]
            brange = [grange[1] + 1, spec_range[1]]
            # ensure each range contains at least one pixel
            rrange[1] = max(rrange)
            grange[1] = max(grange)
            brange[1] = max(brange)

            # FIXME: unoptimized, as each channel is duplicated 3 times, and discarded
            av_data = numpy.mean(data[rrange[0]:rrange[1] + 1], axis=0)
            rgbim = img.DataArray2RGB(av_data, irange)
            av_data = numpy.mean(data[grange[0]:grange[1] + 1], axis=0)
            gim = img.DataArray2RGB(av_data, irange)
            rgbim[:, :, 1] = gim[:, :, 0]
            av_data = numpy.mean(data[brange[0]:brange[1] + 1], axis=0)
            bim = img.DataArray2RGB(av_data, irange)
            rgbim[:, :, 2] = bim[:, :, 0]

        im = NDImage2wxImage(rgbim)
        im.InitAlpha() # it's a different buffer so useless to do it in numpy

        self.image.value = InstrumentalImage(im,
                                             self._findMPP(data),
                                             self._findPos(data))

    def get_spectrum_range(self):
        """
        Return the wavelength for each pixel of a (complete) spectrum
        returns (list of numbers or None): one wavelength per spectrum pixel.
          Values are in meters, unless the spectrum cannot be determined, in
          which case integers representing pixels index is returned.
          If no data is available, None is returned.
        """
        # TODO return unit too? (i.e., m or px)
        if not self.raw:
            return None

        data = self.raw[0]
        try:
            return self._get_wavelength_per_pixel(data)
        except (ValueError, KeyError):
            # useless polynomial => just show pixels values (ex: -50 -> +50 px)
            max_bw = data.shape[0] // 2
            min_bw = (max_bw - data.shape[0]) + 1
            return range(min_bw, max_bw + 1)

    def get_pixel_spectrum(self):
        """ Return the spectrum belonging to the selected pixel or None if no
        spectrum is selected.
        """
        if self.selected_pixel.value != (None, None):
            x, y = self.selected_pixel.value
            return self.raw[0][:, 0, 0, y, x]
        return None

    @limit_invocation(0.1) # Max 10 Hz
    def _updateImage(self):
        """ Recomputes the image with all the raw data available
          Note: for spectrum-based data, it mostly computes a projection of the
          3D data to a 2D array. The type of projection used depends on
          self.projection.
        """
        # check to avoid running it if there is already one running
        if self._running_upd_img or not self.raw:
            return

        try:
            self._running_upd_img = True
            data = self.raw[0][:, 0, 0, :, :]
            self._updateImageAverage(data)
        except Exception:
            logging.exception("Updating %s image", self.__class__.__name__)
        finally:
            self._running_upd_img = False

    # TODO: have an "area=None" argument which allows to specify the 2D region
    # within which the spectrum should be computed
    # TODO: should it also return the wavelength values? Or maybe another method
    # can do it?
    def getMeanSpectrum(self):
        """
        Compute the global spectrum of the data as an average over all the pixels
        returns (numpy.ndarray of float): average intensity for each wavelength
         You need to use the metadata of the raw data to find out what is the
         wavelength for each pixel, but the range of wavelengthBandwidth is
         the same as the range of this spectrum.
        """
        if not self.raw:
            return []

        data = numpy.array(self.raw[0])
        # flatten all but the C dimension, for the average
        data = data.reshape((data.shape[0], numpy.prod(data.shape[1:])))
        av_data = numpy.mean(data, axis=1)

        return av_data

    def onFitToRGB(self, value):
        """
        called when fitToRGB is changed
        """
        self._updateImage()

    def onSpectrumBandwidth(self, value):
        """
        called when spectrumBandwidth is changed
        """
        self._updateImage()

class MultipleDetectorStream(Stream):
    """
    Abstract class for all specialized streams which are actually a combination
    of multiple streams acquired simultaneously. The main difference from a
    normal stream is the init arguments are Streams, and .raw is composed of all
    the .raw from the sub-streams.
    """
    def __init__(self, name, streams):
        """
        streams (list of Streams): all the sub-streams that are used to
            decompose
        """
        # don't call the init of Stream, or it will override .raw
        self.name = model.StringVA(name)
        self._streams = streams

    @property
    def raw(self):
        # build the .raw from all the substreams
        r = []
        for s in self._streams:
            r.extend(s.raw)
        return r

class SEMCCDMDStream(MultipleDetectorStream):
    """
    Abstract class for multiple detector Stream made of SEM + CCD.
    It handles acquisition, but not rendering (so .image always returns an empty
    image).
    It provides to subclasses two ways to acquire the data:
     * software synchronised = the acquisition code takes care of moving the
       SEM spot and starts a new CCD acquisition at each spot. A bit more
       overhead but very reliable, so use for long dwell times.
     * driver synchronised = the SEM is programmed to scan the whole grid and
       automatically synchronises the CCD. As the dwell time is constant, it
       must be bigger than the worst time for CCD acquisition. Less overhead,
       so good for short dwell times.
    TODO: in software synchronisation, we can easily do our own fuzzing.
    """
    __metaclass__ = ABCMeta
    def __init__(self, name, sem_stream, ccd_stream):
        MultipleDetectorStream.__init__(self, name, [sem_stream, ccd_stream])

        self._sem_stream = sem_stream
        self._ccd_stream = ccd_stream

        assert sem_stream._emitter == ccd_stream._emitter
        self._emitter = sem_stream._emitter
        # probably secondary electron detector
        self._semd = self._sem_stream._detector
        self._semd_df = self._sem_stream._dataflow
        self._ccd = self._ccd_stream._detector # CCD
        self._ccd_df = self._ccd_stream._dataflow

        # it will always be an empty image, but a different one every time a new
        # acquisition is finished (so subscribing to it, will at least work).
        self.image = VigilantAttribute(InstrumentalImage(None))

        # For the acquisition
        self._acq_lock = threading.Lock()
        self._acq_state = RUNNING
        self._acq_sem_complete = threading.Event()
        self._acq_ccd_complete = threading.Event()
        self._acq_thread = None # thread
        self._acq_ccd_tot = 0 # number of CCD acquisitions to do
        self._acq_ccd_n = 0 # number of CCD acquisitions so far
        self._acq_start = 0 # time of acquisition beginning
        self._sem_data = None
        self._ccd_data = None

        self._current_future = None

        self.should_update = model.BooleanVA(False)
        self.is_active = model.BooleanVA(False)

    def estimateAcquisitionTime(self):
        # that's the same as the CCD stream (and SEM stream, once the hardware
        # settings are correct)
        return self._ccd_stream.estimateAcquisitionTime()

    def acquire(self):
        # TODO: if already acquiring, queue the Future for later acquisition
        if self._current_future != None and not self._current_future.done():
            raise IOError("Cannot do multiple acquisitions simultaneously")

        if self._acq_thread and self._acq_thread.isAlive():
            logging.debug("Waiting for previous acquisition to fully finish")
            self._acq_thread.join(10)
            if self._acq_thread.isAlive():
                logging.error("Previous acquisition not ending")

        est_start = time.time() + 0.1
        f = model.ProgressiveFuture(start=est_start,
                                    end=est_start + self.estimateAcquisitionTime())
        self._current_future = f
        self._acq_state = RUNNING # TODO: move to per acquisition

        # Pick the right acquisition method
        if self._ccd.exposureTime.value <= 0.1:
            # short dwell time => use driver synchronisation
            runAcquisition = self._dsRunAcquisition
            f.task_canceller = self._dsCancelAcquisition
        else:
            # long dwell time => use software synchronisation
            runAcquisition = self._ssRunAcquisition
            f.task_canceller = self._ssCancelAcquisition

        # run task in separate thread
        self._acq_thread = threading.Thread(target=self._executeTask,
                              name="SEM/CCD acquisition",
                              args=(f, runAcquisition, f))
        self._acq_thread.start()
        return f

    # Copy from acqmng
    @staticmethod
    def _executeTask(future, fn, *args, **kwargs):
        """
        Executes a task represented by a future.
        Usually, called as main task of a (separate thread).
        Based on the standard futures code _WorkItem.run()
        future (Future): future that is used to represent the task
        fn (callable): function to call for running the future
        *args, **kwargs: passed to the fn
        returns None: when the task is over (or cancelled)
        """
        if not future.set_running_or_notify_cancel():
            return

        try:
            result = fn(*args, **kwargs)
        except BaseException:
            e = sys.exc_info()[1]
            future.set_exception(e)
        else:
            future.set_result(result)

    @abstractmethod
    def _onSEMCCDData(self, sem_data, ccd_data):
        """
        called at the end of an entire acquisition
        sem_data (DataArray): the SEM data
        ccd_data (list of DataArray): the CCD data (ordered, with X changing
          fast, then Y slow)
        """
        pass

    def _updateProgress(self, future, start, ratio):
        """
        update end time of future
        future (ProgressiveFuture): future to update
        start (float): start time
        ratio (0<=float<=1): progress ratio
        """
        now = time.time()
        tot_time = (now - start) / ratio
        # add some overhead for the end of the acquisition
        future.set_end_time(start + tot_time + 0.1)

    def _ssCancelAcquisition(self, future):
        with self._acq_lock:
            if self._acq_state == FINISHED:
                return False # too late
            self._acq_state = CANCELLED

        msg = ("Cancelling acquisition of components %s and %s")
        logging.debug(msg, self._semd.name, self._ccd.name)

        # Do it in any case, to be sure
        self._semd_df.unsubscribe(self._ssOnSEMImage)
        self._ccd_df.unsubscribe(self._ssOnCCDImage)
        self._ccd_df.synchronizedOn(None)
        # set the events, so the acq thread doesn't wait for them
        self._acq_ccd_complete.set()
        self._acq_sem_complete.set()
        return True

    def _ssAdjustHardwareSettings(self):
        """
        Read the SEM and AR stream settings and adapt the SEM scanner
        accordingly.
        return (float): estimated time for a whole CCD image
        """
        # Set SEM to spot mode, without caring about actual position (set later)
        self._emitter.scale.value = (1, 1) # min, to avoid limits on translation
        self._emitter.resolution.value = (1, 1)

        # Dwell Time: a "little bit" more than the exposure time
        exp = self._ccd.exposureTime.value #s
        ccd_size = self._ccd.resolution.value

        # Dwell time as long as possible, but better be slightly shorter than
        # CCD to be sure it is not slowing thing down.
        readout = numpy.prod(ccd_size) / self._ccd.readoutRate.value
        rng = self._emitter.dwellTime.range
        self._emitter.dwellTime.value = sorted(rng + (exp + readout,))[1] # clip

        return exp + readout

    def _getSpotPositions(self):
        """
        Compute the positions of the e-beam for each point in the ROI
        return (numpy ndarray of floats of shape (X,Y,2)): each value is for a
          given X/Y in the repetition grid -> 2 floats corresponding to the
          translation.
        """
        repetition = tuple(self._ccd_stream.repetition.value)
        roi = self._ccd_stream.roi.value
        width = (roi[2] - roi[0], roi[3] - roi[1])

        # Take into account the "border" around each pixel
        pxs = (width[0] / repetition[0], width[1] / repetition[1])
        lim = (roi[0] + pxs[0] / 2, roi[1] + pxs[1] / 2,
               roi[2] - pxs[0] / 2, roi[3] - pxs[1] / 2)

        shape = self._emitter.shape
        # convert into SEM translation coordinates: distance in px from center
        # (situated at 0.5, 0.5), can be floats
        lim_sem = (shape[0] * (lim[0] - 0.5), shape[1] * (lim[1] - 0.5),
                   shape[0] * (lim[2] - 0.5), shape[1] * (lim[3] - 0.5))
        logging.debug("Generating points in the SEM area %s", lim_sem)

        pos = numpy.empty(repetition + (2,), dtype=numpy.float)
        posx = pos[:, :, 0].swapaxes(0, 1) # just a view to have X as last dim
        posx[:, :] = numpy.linspace(lim_sem[0], lim_sem[2], repetition[0])
        # fill the X dimension
        pos[:, :, 1] = numpy.linspace(lim_sem[1], lim_sem[3], repetition[1])
        return pos

    def _ssRunAcquisition(self, future):
        """
        Acquires SEM/CCD images via software synchronisation.
        Warning: can be quite memory consuming if the grid is big
        returns (list of DataArray): all the data acquired
        raises:
          CancelledError() if cancelled
          Exceptions if error
        """
        # TODO: handle better very large grid acquisition (than memory oops)
        try:
            ccd_time = self._ssAdjustHardwareSettings()
            dwell_time = self._emitter.dwellTime.value
            spot_pos = self._getSpotPositions()
            logging.debug("Generating %s spots for %g (=%g) s", spot_pos.shape[:2], ccd_time, dwell_time)
            rep = self._ccd_stream.repetition.value
            roi = self._ccd_stream.roi.value
            self._sem_data = []
            self._ccd_data = None
            ccd_buf = []
            self._ccd_stream.raw = []
            self._sem_stream.raw = []
            logging.debug("Starting CCD acquisition with components %s and %s",
                          self._semd.name, self._ccd.name)

            # We need to use synchronisation event because without it, either we
            # use .get() but it's not possible to cancel the acquisition, or we
            # subscribe/unsubscribe for each image, but the overhead is high.
            trigger = self._ccd.softwareTrigger
            self._ccd_df.synchronizedOn(trigger)
            self._ccd_df.subscribe(self._ssOnCCDImage)

            tot_num = numpy.prod(rep)
            n = 0
            start_time = time.time()
            for i in numpy.ndindex(*rep[::-1]): # last dim (X) iterates first
                # set ebeam to position (which is ensured only once acquiring)
                self._emitter.translation.value = spot_pos[i[::-1]]
                self._acq_sem_complete.clear()
                self._acq_ccd_complete.clear()
                self._semd_df.subscribe(self._ssOnSEMImage)
                time.sleep(0) # give more chances spot has been already processed
                start = time.time()
                trigger.notify()

                if not self._acq_ccd_complete.wait(ccd_time * 2 + 1):
                    raise TimeoutError("Acquisition of CCD for pixel %s timed out" % (i,))
                if self._acq_state == CANCELLED:
                    raise CancelledError()
                dur = time.time() - start
                if dur < ccd_time:
                    logging.warning("CCD acquisition took less that %g s: %g s",
                                    ccd_time, dur)

                # Normally, the SEM acquisition has already completed
                if not self._acq_sem_complete.wait(dwell_time * 1.5 + 1):
                    raise TimeoutError("Acquisition of SEM pixel %s timed out" % (i,))
                # TODO: we don't really need to stop it, we could have a small
                # dwell time, move the ebeam to the new position, and as soon as
                # we get next acquisition we can expect the spot has moved. The
                # advantage would be to avoid setting the ebeam back to resting
                # position, and reduce overhead of stopping/starting.
                self._semd_df.unsubscribe(self._ssOnSEMImage)

                if self._acq_state == CANCELLED:
                    raise CancelledError()

                # MD_POS default to the center of the stage, but it needs to be
                # the position of the e-beam
                ccd_data = self._ccd_data
                ccd_data.metadata[MD_POS] = self._sem_data[-1].metadata[MD_POS]
                ccd_data.metadata[MD_DESCRIPTION] = self._ccd_stream.name.value
                ccd_buf.append(ccd_data)

                n += 1
                self._updateProgress(future, start_time, n / tot_num)

            self._ccd_df.unsubscribe(self._ssOnCCDImage)
            self._ccd_df.synchronizedOn(None)

            with self._acq_lock:
                if self._acq_state == CANCELLED:
                    raise CancelledError()
                self._acq_state = FINISHED

            sem_one = self._assembleSEMData(rep, roi, self._sem_data) # shape is (Y, X)
            # explicitly add names to make sure they are different
            sem_one.metadata[MD_DESCRIPTION] = self._sem_stream.name.value
            self._onSEMCCDData(sem_one, ccd_buf)
        except Exception as exp:
            if not isinstance(exp, CancelledError):
                logging.exception("Software sync acquisition of SEM/CCD failed")

            # make sure it's all stopped
            self._semd_df.unsubscribe(self._ssOnSEMImage)
            self._ccd_df.unsubscribe(self._ssOnCCDImage)
            self._ccd_df.synchronizedOn(None)

            self._ccd_stream.raw = []
            self._sem_stream.raw = []
            if not isinstance(exp, CancelledError) and self._acq_state == CANCELLED:
                logging.warning("Converting exception to cancellation")
                raise CancelledError()
            raise
        else:
            return self.raw
        finally:
            del self._sem_data # regain a bit of memory

    def _ssOnSEMImage(self, df, data):
        logging.debug("SEM data received")
        # Do not stop the acquisition, as it ensures the e-beam is at the right place
        if not self._acq_sem_complete.is_set():
            # only use the first data per pixel
            self._sem_data.append(data)
            self._acq_sem_complete.set()

    def _ssOnCCDImage(self, df, data):
        logging.debug("CCD data received")
        self._ccd_data = data
        self._acq_ccd_complete.set()

    def _assembleSEMData(self, rep, roi, data_list):
        """
        Take all the data received from the SEM and assemble it in a 2D image.
        The result goes into .raw.

        rep (tuple of 2 0<ints): X/Y repetition
        roi (tupel of 3 0<floats<=1): region of interest in logical coordinates
        data_list (list of M DataArray of shape (1, 1)): all the data received,
        with X variating first, then Y.
        """
        assert len(data_list) > 0

        # start with the metadata from the first point
        md = dict(data_list[0].metadata)

        # Compute center of area, from average of centered acquisitions
        idx_center = rep[0] // 2
        if idx_center * 2 == rep[0]: # even number => average
            posx = (data_list[idx_center - 1].metadata[MD_POS][0] +
                    data_list[idx_center].metadata[MD_POS][0]) / 2
        else: # odd number => center
            posx = data_list[idx_center].metadata[MD_POS][0]
        idx_center = rep[1] // 2
        if idx_center * 2 == rep[1]: # even number => average
            posy = (data_list[rep[0] * (idx_center - 1)].metadata[MD_POS][1] +
                    data_list[rep[0] * idx_center].metadata[MD_POS][1]) / 2
        else: # odd number => center
            posy = data_list[rep[0] * idx_center].metadata[MD_POS][1]

        # Pixel size is the size of field of view divided by the repetition
        sem_pxs = self._emitter.pixelSize.value
        sem_shape = self._emitter.shape[:2]
        width = (roi[2] - roi[0], roi[3] - roi[1])
        fov = (width[0] * sem_shape[0] * sem_pxs[0],
               width[1] * sem_shape[1] * sem_pxs[1])
        pxs = (fov[0] / rep[0], fov[1] / rep[1])

        md.update({MD_POS: (posx, posy),
                   MD_PIXEL_SIZE: pxs})

        # concatenate data into one big array of (number of pixels,1)
        sem_data = numpy.concatenate(data_list)
        # reshape to (Y, X)
        sem_data.shape = rep[::-1]
        sem_data = model.DataArray(sem_data, metadata=md)
        return sem_data

    def _dsCancelAcquisition(self, future):
        with self._acq_lock:
            if self._acq_state == FINISHED:
                return False # too late
            self._acq_state = CANCELLED
        msg = ("Cancelling acquisition of components %s and %s")
        logging.debug(msg, self._semd.name, self._ccd.name)

        self._semd_df.unsubscribe(self._dsOnSEMImage)
        self._ccd_df.unsubscribe(self._dsOnCCDImage)
        self._ccd_df.synchronizedOn(None)
        # set the event, so the acq thread doesn't wait for them
        self._acq_ccd_complete.set()
        self._acq_sem_complete.set()
        return True

    def _dsAdjustHardwareSettings(self):
        """
        Read the SEM and CCD stream settings and adapt the scanner accordingly.
        """
        # ROI
        rep = list(self._ccd_stream.repetition.value)
        roi = self._ccd_stream.roi.value
        center = ((roi[0] + roi[2]) / 2, (roi[1] + roi[3]) / 2)
        width = (roi[2] - roi[0], roi[3] - roi[1])

        shape = self._emitter.shape
        # translation is distance from center (situated at 0.5, 0.5), can be floats
        trans = (shape[0] * (center[0] - 0.5), shape[1] * (center[1] - 0.5))
        # scale is how big is a pixel compared to the minimum pixel size (1/shape)
        scale = (max(1, (shape[0] * width[0]) / rep[0]),
                 max(1, (shape[1] * width[1]) / rep[1]))

        logging.debug("Setting SEM ROI to resolution = %s, translation = %s, and "
                      "scale = %s", rep, trans, scale)

        # always in this order
        self._emitter.scale.value = scale
        self._emitter.resolution.value = rep
        self._emitter.translation.value = trans

        # Dwell Time: a "little bit" more than the exposure time
        exp = self._ccd.exposureTime.value #s
        ccd_size = self._ccd.resolution.value

        # "Magical" formula to get a long enough dwell time. It has to be as
        # long as the maximum CCD acquisition => needs a bit of margin.
        # Works with PVCam and Andorcam2, but not fool proof at all!
        readout = numpy.prod(ccd_size) / self._ccd.readoutRate.value + 0.01
        # 50ms to account for the overhead and extra image acquisition
        dt = (exp + readout) * 1.3 + 0.05
        rng = self._emitter.dwellTime.range
        self._emitter.dwellTime.value = sorted(rng + (dt,))[1] # clip

        # Take into account settle time
        if len(rep) == 2 and rep[1] > 1:
            rep[1] += 1
        tot_time = (self._emitter.dwellTime.value + 0.01) * numpy.prod(rep)

        return tot_time

    def _dsRunAcquisition(self, future):
        """
        Wait until the acquisition is complete, to update the data and stop the
        updates.
        To be run as a separate thread, after the SEM data has arrived.
        return (list of DataArray): all the data acquired
        raises:
          CancelledError() if cancelled
          Exceptions if error
        """
        try:
            # reset everything (ready for one acquisition)
            tot_time = self._dsAdjustHardwareSettings()
            rep = self._ccd_stream.repetition.value
            self._acq_ccd_tot = numpy.prod(rep)
            self._acq_ccd_n = 0
            self._acq_ccd_buf = []
            self._sem_data = None # One DataArray
            self._acq_ccd_complete.clear()
            self._acq_sem_complete.clear()

            self._ccd_df.synchronizedOn(self._emitter.newPosition)
            self._ccd_df.subscribe(self._dsOnCCDImage)
            self._acq_start = time.time()
            self._semd_df.subscribe(self._dsOnSEMImage)

            # Wait until it's all done
            if not self._acq_ccd_complete.wait(tot_time * 1.5 + 1):
                raise TimeoutError("Acquisition of SEM/CCD timed out")
            if not self._acq_sem_complete.wait(self._emitter.dwellTime.value + 1):
                raise TimeoutError("Acquisition of SEM/CCD timed out")
            self._ccd_df.synchronizedOn(None)

            with self._acq_lock:
                if self._acq_state == CANCELLED:
                    raise CancelledError()
                self._acq_state = FINISHED

            # actually only useful for AR acquisition
            sem_md = self._sem_data.metadata
            pos = sem_md[MD_POS]
            pxs = sem_md[MD_PIXEL_SIZE]
            self._dsUpdateCCDMetadata(self._acq_ccd_buf, rep, pos, pxs)

            # explicitly add names to make sure they are different
            ccd_stream_name = self._ccd_stream.name.value
            for d in self._acq_ccd_buf:
                d.metadata[MD_DESCRIPTION] = ccd_stream_name
            sem_md[MD_DESCRIPTION] = self._sem_stream.name.value
            self._onSEMCCDData(self._sem_data, self._acq_ccd_buf)
        except Exception as exp:
            if not isinstance(exp, CancelledError):
                logging.exception("Driver sync acquisition of SEM/CCD failed")

            # make sure it's all stopped
            self._semd_df.unsubscribe(self._dsOnSEMImage)
            self._ccd_df.unsubscribe(self._dsOnCCDImage)
            self._ccd_df.synchronizedOn(None)

            self._ccd_stream.raw = []
            self._sem_stream.raw = []
            if not isinstance(exp, CancelledError) and self._acq_state == CANCELLED:
                logging.warning("Converting exception to cancellation")
                raise CancelledError()
            raise
        else:
            return self.raw
        finally:
            del self._acq_ccd_buf # regain a bit of memory

    def _dsUpdateCCDMetadata(self, das, rep, pos, pxs):
        """
        Updates the MD_POS metadata of the CCD data (=spot position)
        das (list of DataArrays): X*Y data, ordered in X, then Y scan
        rep (tuple of 2 int): dimension of X and Y
        pos (tuple of 2 float): center
        pxs (tuple of 2 float): physical distance between spots
        returns nothing, just updates das
        """
        pos0 = (pos[0] - (pxs[0] * (rep[0] - 1) / 2),
                pos[1] - (pxs[1] * (rep[1] - 1) / 2))
        for idx, d in zip(numpy.ndindex(*rep[::-1]), das):
            # rep is reversed as numpy scans last dim first
            d.metadata[MD_POS] = (pos0[0] + idx[1] * pxs[0],
                                  pos0[1] + idx[0] * pxs[1])

    def _dsOnCCDImage(self, df, data):
        # the data array subscribers must be fast, so the real processing
        # takes place later
        self._acq_ccd_buf.append(data)
        # TODO: update the estimated time based on how long it takes per pixel
        # in reality

        self._acq_ccd_n += 1
        ratio = self._acq_ccd_n / self._acq_ccd_tot
        self._updateProgress(self._current_future, self._acq_start, ratio)
        if self._acq_ccd_n >= self._acq_ccd_tot:
            # unsubscribe to stop immediately
            df.unsubscribe(self._dsOnCCDImage)
            self._acq_ccd_complete.set()

    def _dsOnSEMImage(self, df, data):
        # unsubscribe to stop immediately
        df.unsubscribe(self._dsOnSEMImage)
        self._sem_data = data
        self._acq_sem_complete.set()

class SEMSpectrumMDStream(SEMCCDMDStream):
    """
    Multiple detector Stream made of SEM + Spectrum.
    It handles acquisition, but not rendering (so .image always returns an empty
    image).
    """

    def _onSEMCCDData(self, sem_data, ccd_data):
        """
        cf SEMCCDMDStream._onSEMCCDData()
        """
        assert ccd_data[0].shape[-2] == 1 # should be a spectra (Y == 1)
        repetition = sem_data.shape[-1:-3:-1] # 1,1,1,Y,X -> X, Y

        # assemble all the CCD data into one
        spec_data = self._assembleSpecData(ccd_data, repetition)
        md_sem = sem_data.metadata
        try:
            spec_data.metadata[MD_PIXEL_SIZE] = md_sem[MD_PIXEL_SIZE]
            spec_data.metadata[MD_POS] = md_sem[MD_POS]
        except KeyError:
            logging.warning("Metadata missing from the SEM data")

        # save the new data
        self._ccd_stream.raw = [spec_data]
        self._sem_stream.raw = [sem_data]

    def _assembleSpecData(self, data_list, repetition):
        """
        Take all the data received from the spectrometer and assemble it in a
        cube.

        data_list (list of M DataArray of shape (1, N)): all the data received
        repetition (list of 2 int): X,Y shape of the high dimensions of the cube
         so that X * Y = M
        return (DataArray)
        """
        assert len(data_list) > 0

        # each element of acq_spect_buf has a shape of (1, N)
        # reshape to (N, 1)
        for e in data_list:
            e.shape = e.shape[::-1]
        # concatenate into one big array of (N, number of pixels)
        spec_data = numpy.concatenate(data_list, axis=1)
        # reshape to (C, 1, 1, Y, X) (as C must be the 5th dimension)
        spec_res = data_list[0].shape[0]
        spec_data.shape = (spec_res, 1, 1, repetition[1], repetition[0])

        # copy the metadata from the first point and add the ones from metadata
        md = data_list[0].metadata
        return model.DataArray(spec_data, metadata=md)


class SEMARMDStream(SEMCCDMDStream):
    """
    Multiple detector Stream made of SEM + AR.
    It handles acquisition, but not rendering (so .image always returns an empty
    image).
    """

    def _onSEMCCDData(self, sem_data, ccd_data):
        """
        cf SEMCCDMDStream._onSEMCCDData()
        """
        # Not much to do: just save everything as is

        # MD_AR_POLE is set automatically, copied from the lens property.
        # In theory it's dependant on MD_POS, but so slightly that we don't need
        # to correct it.
        self._ccd_stream.raw = ccd_data
        self._sem_stream.raw = [sem_data]

# On the SPARC, it's possible that both the AR and Spectrum are acquired in the
# same acquisition, but it doesn't make much sense to acquire them
# simultaneously because the two optical detectors need the same light, and a
# mirror is used to select which path is taken. In addition, the AR stream will
# typically have a lower repetition (even if it has same ROI). So it's easier
# and faster to acquire them sequentially. The only trick is that if drift
# correction is used, the same correction must be used for the entire
# acquisition.

# Generic cross-cut types
# All the stream types related to optical
OPTICAL_STREAMS = (FluoStream,
                   BrightfieldStream,
                   StaticFluoStream,
                   StaticBrightfieldStream)

# All the stream types related to electron microscope
EM_STREAMS = (SEMStream,
              StaticSEMStream)

SPECTRUM_STREAMS = (SpectrumStream,
                    StaticSpectrumStream)

AR_STREAMS = (ARStream,
              StaticARStream)

# TODO: make it like a VA, so that it's possible to know when it changes
class StreamTree(object):
    """ Object which contains a set of streams, and how they are merged to
    appear as one image. It's a tree which has one stream per leaf and one merge
    operation per node. => recursive structure (= A tree is just a node with
    a merge method and a list of subnodes, either streamtree as well, or stream)
    """

    def __init__(self, operator=None, streams=None, **kwargs):
        """
        :param operator: (callable) a function that takes a list of
            InstrumentalImage in the same order as the streams are given and the
            additional arguments and returns one InstrumentalImage.
            By default operator is an average function.
        :param streams: (list of Streams or StreamTree): a list of streams, or
            StreamTrees.
            If a StreamTree is provided, its outlook is first computed and then
            passed as an InstrumentalImage.
        :param kwargs: any argument to be given to the operator function
        """
        self.operator = operator or img.Average

        streams = streams or []
        assert(isinstance(streams, list))

        self.streams = []
        self.should_update = model.BooleanVA(False)
        self.kwargs = kwargs

        for s in streams:
            self.add_stream(s)

    def __str__(self):
        return "[" + ", ".join([str(s) for s in self.streams]) + "]"

    def __len__(self):
        acc = 0

        for s in self.streams:
            if isinstance(s, Stream):
                acc += 1
            elif isinstance(s, StreamTree):
                acc += len(s)

        return acc

    def __getitem__(self, index):
        """ Return the Stream of StreamTree using index reference val[i] """
        return self.streams[index]

    def add_stream(self, stream):
        if isinstance(stream, (Stream, StreamTree)):
            self.streams.append(stream)
            if hasattr(stream, 'should_update'):
                stream.should_update.subscribe(self.stream_update_changed,
                                               init=True)
            # print "stream added %s" % stream.should_update.value
        else:
            msg = "Illegal type %s found in add_stream!" % type(stream)
            raise ValueError(msg)

    def remove_stream(self, stream):
        if hasattr(stream, 'should_update'):
            stream.should_update.unsubscribe(self.stream_update_changed)
        self.streams.remove(stream)
        self.stream_update_changed()

    def stream_update_changed(self, should_update=None):
        """ This method is called when one of the streams' should_update
        vigilant attribute changes.
        """
        # At least one stream is live, so we 'should update'
        for s in self.streams:
            if hasattr(s, "should_update") and s.should_update.value:
                self.should_update.value = True
                break
        else:
            self.should_update.value = False

    def getStreams(self):
        """
        Return the set of streams used to compose the picture. In other words,
        the leaves of the tree.
        """
        leaves = set()
        for s in self.streams:
            if isinstance(s, Stream):
                leaves.add(s)
            elif isinstance(s, StreamTree):
                leaves |= s.getStreams()

        return leaves

    def getImage(self, rect, mpp):
        """
        Returns an InstrumentalImage composed of all the current stream images.
        Precisely, it returns the output of a call to operator.
        rect (2-tuple of 2-tuple of float): top-left and bottom-right points in
          world position (m) of the area to draw
        mpp (0<float): density (meter/pixel) of the image to compute
        """
        # TODO: probably not so useful function, need to see what canvas
        #  it will likely need as argument a wx.Bitmap, and view rectangle
        #  that will define where to save the result

        # TODO: cache with the given rect and mpp and last update time of each
        # image

        # create the arguments list for operator
        images = []
        for s in self.streams:
            if isinstance(s, Stream):
                images.append(s.image.value)
            elif isinstance(s, StreamTree):
                images.append(s.getImage(rect, mpp))


        return self.operator(images, rect, mpp, **self.kwargs)

    def getRawImages(self):
        """
        Returns a list of all the raw images used to create the final image
        """
        # TODO not sure if a list is enough, we might need to return more
        # information about how the image was built (operator, args...)
        lraw = []
        for s in self.getStreams():
            lraw.extend(s.raw)

        return lraw

    @property
    def spectrum_streams(self):
        """ Return a flat list of spectrum streams """
        return self.get_streams(SPECTRUM_STREAMS)

    @property
    def angle_resolve_streams(self):
        """ Return a flat list of spectrum streams """
        return self.get_streams(AR_STREAMS)

    def get_streams_by_name(self, name):
        """ Return a list of streams with have names that match `name` """

        leaves = set()
        for s in self.streams:
            if isinstance(s, Stream) and s.name.value == name:
                leaves.add(s)
            elif isinstance(s, StreamTree):
                leaves |= s.get_streams_by_name(name)

        return list(leaves)

    def get_streams(self, stream_types):
        """ Return a flat list of streams of `stream_type` within the StreamTree
        """
        streams = []

        for s in self.streams:
            if isinstance(s, StreamTree):
                streams.extend(s._get_streams(stream_types))
            elif isinstance(s, stream_types):
                streams.append(s)

        return streams
